{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af4c8a9-98e4-4d1e-900e-2508e24cffbb",
   "metadata": {},
   "source": [
    "# Test environment (no render)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68329c60-1483-4679-8d67-c45ac7ddd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from crowd_sim.envs.crowd_sim_sgan import CrowdSimSgan\n",
    "from crowd_sim.envs.crowd_sim_no_pred import CrowdSimNoPred\n",
    "from arguments import get_args\n",
    "from crowd_nav.configs.config import Config\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e54cae-80d5-4d18-ba78-e4944efb7f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CrowdSimNoPred()\n",
    "# env = CrowdSimSgan()\n",
    "env.configure(config)\n",
    "\n",
    "env.setup(seed=0, num_of_env=1, ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1139731-5d3a-45e9-a597-5ff7e9a1502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 1\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    avg_time = 0\n",
    "    step = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = (0.0, 0.0)\n",
    "        start_time = time.time()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        end_time = time.time()\n",
    "        avg_time += (end_time - start_time)\n",
    "        step += 1\n",
    "        score+=reward\n",
    "        print(obs['local_goal'])\n",
    "        plt.imshow(obs['local_map'].reshape(obs['local_map'].shape[0],obs['local_map'].shape[1]), cmap='gray')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "    print('average step time ({} steps): {}s'.format(step, avg_time/step))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae5c55a-f810-40b6-9462-492b8e074fa0",
   "metadata": {},
   "source": [
    "# Test environment (render simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28dae2-0300-4c89-890d-fe151e09d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "from crowd_sim.envs.crowd_sim_sgan import CrowdSimSgan\n",
    "from crowd_sim.envs.crowd_sim_no_pred import CrowdSimNoPred\n",
    "from arguments import get_args\n",
    "from crowd_nav.configs.config import Config\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a42e5ac-f19c-4dc3-b0a4-16faa6f88222",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax1 = plt.subplot()\n",
    "ax1.set_xlim(-10, 10)\n",
    "ax1.set_ylim(-10, 10)\n",
    "ax1.set_xlabel('x(m)', fontsize=16)\n",
    "ax1.set_ylabel('y(m)', fontsize=16)\n",
    "\n",
    "plt.ion()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218cbefb-c697-4b9c-928c-8159da80d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CrowdSimNoPred()\n",
    "# env = CrowdSimSgan()\n",
    "env.configure(config)\n",
    "\n",
    "env.setup(seed=0, num_of_env=1, ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b419d477-4cb2-4f48-adaa-600a70c451e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 1\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    avg_time = 0\n",
    "    step = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = (1.0, 1.0)\n",
    "        start_time = time.time()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        end_time = time.time()\n",
    "        avg_time += (end_time - start_time)\n",
    "        step += 1\n",
    "        score+=reward\n",
    "        print(obs['local_goal'])\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "    print('average step time ({} steps): {}s'.format(step, avg_time/step))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6406025-1525-47a7-aa13-5b4b11b01a07",
   "metadata": {},
   "source": [
    "# Training RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e97b4997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koksyuen/anaconda3/envs/rl/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from crowd_sim.envs.crowd_sim_sgan import CrowdSimSgan\n",
    "from crowd_sim.envs.crowd_sim_no_pred import CrowdSimNoPred\n",
    "import gym\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0334ee30-7888-4efc-9071-3d2b52eb20d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3 import PPO, A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfafa5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arguments import get_args\n",
    "from crowd_nav.configs.config import Config\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a1b115-cce8-4526-b9a0-fee52120b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import os\n",
    "\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf52c12e-604b-4756-bbdf-ccc876261483",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/PPO2/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3851ea5-2e01-4e50-83c8-728a68592c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CrowdSimNoPred()\n",
    "# env = CrowdSimSgan()\n",
    "env.configure(config)\n",
    "env.setup(seed=0, num_of_env=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cebdf14-65ef-428f-9943-f43c46aa8c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72f5eb6d-3302-4db1-aaa0-41cf058ffd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# model = PPO('MultiInputPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.000001, \n",
    "#             n_steps=512) \n",
    "model = PPO('MultiInputPolicy', env, verbose=1, tensorboard_log=LOG_DIR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cfbda1a-bfe8-4053-a53e-f9aa426fff44",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiInputActorCriticPolicy(\n",
       "  (features_extractor): CombinedExtractor(\n",
       "    (extractors): ModuleDict(\n",
       "      (local_goal): Flatten(start_dim=1, end_dim=-1)\n",
       "      (local_map): NatureCNN(\n",
       "        (cnn): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "          (3): ReLU()\n",
       "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (5): ReLU()\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (linear): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): CombinedExtractor(\n",
       "    (extractors): ModuleDict(\n",
       "      (local_goal): Flatten(start_dim=1, end_dim=-1)\n",
       "      (local_map): NatureCNN(\n",
       "        (cnn): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "          (3): ReLU()\n",
       "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (5): ReLU()\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (linear): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): CombinedExtractor(\n",
       "    (extractors): ModuleDict(\n",
       "      (local_goal): Flatten(start_dim=1, end_dim=-1)\n",
       "      (local_map): NatureCNN(\n",
       "        (cnn): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "          (3): ReLU()\n",
       "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (5): ReLU()\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (linear): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=258, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=258, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4360a9b5-3bd3-43ad-8377-572a7f304847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/PPO_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 84.8     |\n",
      "|    ep_rew_mean     | -15.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 62       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 85.2         |\n",
      "|    ep_rew_mean          | -16.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024189902 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.00427      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.86         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00727     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 10.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 80.4         |\n",
      "|    ep_rew_mean          | -15.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036192934 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 7.14         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 81           |\n",
      "|    ep_rew_mean          | -16.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036008242 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.9         |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.71         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000452    |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 5.35         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 81.7         |\n",
      "|    ep_rew_mean          | -16.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035383143 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.91        |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.514        |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 5.05         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 83.3         |\n",
      "|    ep_rew_mean          | -16.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 224          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031907216 |\n",
      "|    clip_fraction        | 0.00796      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.92        |\n",
      "|    explained_variance   | 0.381        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.415        |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 3.95         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 92.7         |\n",
      "|    ep_rew_mean          | -15.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063270284 |\n",
      "|    clip_fraction        | 0.037        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.92        |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.724        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00697     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 4.67         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.5        |\n",
      "|    ep_rew_mean          | -14.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006446569 |\n",
      "|    clip_fraction        | 0.0325      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.92       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.513       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -13.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 324          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063482663 |\n",
      "|    clip_fraction        | 0.0541       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.92        |\n",
      "|    explained_variance   | 0.53         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.73         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 3.56         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 104         |\n",
      "|    ep_rew_mean          | -11.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 357         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009800612 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.527       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 3.46        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | -11         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010355206 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.92       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.247       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 3.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 93.2        |\n",
      "|    ep_rew_mean          | -11.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 423         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010909721 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.91       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.882       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 4.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 88          |\n",
      "|    ep_rew_mean          | -11.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 457         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010402941 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.9        |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.291       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 3.86        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80.9        |\n",
      "|    ep_rew_mean          | -12.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 490         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015521741 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.9        |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 4.15        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.8       |\n",
      "|    ep_rew_mean          | -11.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 524        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01634114 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.89      |\n",
      "|    explained_variance   | 0.503      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.689      |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0118    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 3.62       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.5        |\n",
      "|    ep_rew_mean          | -11.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018607486 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.5        |\n",
      "|    ep_rew_mean          | -10.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 591         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022966841 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.798       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.2        |\n",
      "|    ep_rew_mean          | -10.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 625         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017200977 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.476       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.6        |\n",
      "|    ep_rew_mean          | -10.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 658         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023355462 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.281       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 5.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.2        |\n",
      "|    ep_rew_mean          | -10.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 692         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019287031 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.367       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.73        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82.2        |\n",
      "|    ep_rew_mean          | -9.36       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 725         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024960184 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.86        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 97.4        |\n",
      "|    ep_rew_mean          | -7.19       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 758         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023565352 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.867       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98.3        |\n",
      "|    ep_rew_mean          | -6.26       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 791         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022201117 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.203       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 0.987       |\n",
      "|    value_loss           | 2.11        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    301\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py:250\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    247\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 250\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py:178\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mBox):\n\u001b[1;32m    176\u001b[0m     clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 178\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:163\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.8/site-packages/stable_baselines3/common/vec_env/vec_transpose.py:95\u001b[0m, in \u001b[0;36mVecTransposeImage.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m---> 95\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# Transpose the terminal observations\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, done \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dones):\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:60\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n\u001b[0;32m---> 60\u001b[0m         obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs_from_buf(), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones), deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos))\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.8/site-packages/stable_baselines3/common/monitor.py:84\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_reset_info[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_project/CrowdNav_Prediction_AttnGraph/crowd_sim/envs/crowd_sim_no_pred.py:129\u001b[0m, in \u001b[0;36mCrowdSimNoPred.reset\u001b[0;34m(self, phase, test_case)\u001b[0m\n\u001b[1;32m    126\u001b[0m     agent\u001b[38;5;241m.\u001b[39mtime_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step\n\u001b[1;32m    127\u001b[0m     agent\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mtime_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_robot_humans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# record humans' emotion\u001b[39;00m\n",
      "File \u001b[0;32m~/python_project/CrowdNav_Prediction_AttnGraph/crowd_sim/envs/crowd_sim.py:340\u001b[0m, in \u001b[0;36mCrowdSim.generate_robot_humans\u001b[0;34m(self, phase, human_num)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrobot\u001b[38;5;241m.\u001b[39mset(px, py, gx, gy, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39mpi\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m## generate humans\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_random_human_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhuman_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhuman_num\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_project/CrowdNav_Prediction_AttnGraph/crowd_sim/envs/crowd_sim.py:222\u001b[0m, in \u001b[0;36mCrowdSim.generate_random_human_position\u001b[0;34m(self, human_num)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# initial min separation distance to avoid danger penalty at beginning\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(human_num):\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhumans\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_circle_crossing_human\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/python_project/CrowdNav_Prediction_AttnGraph/crowd_sim/envs/crowd_sim.py:249\u001b[0m, in \u001b[0;36mCrowdSim.generate_circle_crossing_human\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     min_dist \u001b[38;5;241m=\u001b[39m human\u001b[38;5;241m.\u001b[39mradius \u001b[38;5;241m+\u001b[39m agent\u001b[38;5;241m.\u001b[39mradius \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscomfort_dist\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m norm((px \u001b[38;5;241m-\u001b[39m agent\u001b[38;5;241m.\u001b[39mpx, py \u001b[38;5;241m-\u001b[39m agent\u001b[38;5;241m.\u001b[39mpy)) \u001b[38;5;241m<\u001b[39m min_dist \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[0;32m--> 249\u001b[0m         \u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m min_dist:\n\u001b[1;32m    250\u001b[0m     collide \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.8/site-packages/numpy/linalg/linalg.py:2512\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2511\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdot(x)\n\u001b[0;32m-> 2512\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n\u001b[1;32m   2514\u001b[0m     ret \u001b[38;5;241m=\u001b[39m ret\u001b[38;5;241m.\u001b[39mreshape(ndim\u001b[38;5;241m*\u001b[39m[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=2000000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abbe8b8-6e79-4d01-989f-de08f92b39df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('latestmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c027158-a1d0-4883-be13-79947d9961e2",
   "metadata": {},
   "source": [
    "# 4. Test it Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb3194-195d-4e7a-8a29-406d7c6d485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crowd_sim.envs.crowd_sim_sgan import CrowdSimSgan\n",
    "from crowd_sim.envs.crowd_sim_no_pred import CrowdSimNoPred\n",
    "import gym\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e5719c-f35f-4a6d-8019-ed1d32b23920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3 import PPO, A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07fc9f2-fa54-4472-946b-f4e4a5421921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arguments import get_args\n",
    "from crowd_nav.configs.config import Config\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f132f2e-90bf-4940-8c63-2ee995b82ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe15991-1bee-43fe-9ee7-852e09a64b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax1 = plt.subplot()\n",
    "ax1.set_xlim(-10, 10)\n",
    "ax1.set_ylim(-10, 10)\n",
    "ax1.set_xlabel('x(m)', fontsize=16)\n",
    "ax1.set_ylabel('y(m)', fontsize=16)\n",
    "\n",
    "plt.ion()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf67145-3944-4d78-b787-9621d7f3655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CrowdSimNoPred()\n",
    "# env = CrowdSimSgan()\n",
    "env.configure(config)\n",
    "env.setup(seed=0, num_of_env=1, ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970fb1c-011f-4c84-9009-c6a803567af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = PPO.load('./train/PPO/best_model_50000', env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c04d1d-feee-4e76-8a2b-e9132d103ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    avg_time = 0\n",
    "    step = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _states = model.predict(obs)\n",
    "        start_time = time.time()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        end_time = time.time()\n",
    "        avg_time += (end_time - start_time)\n",
    "        step += 1\n",
    "        score+=reward\n",
    "        print(obs['local_goal'])\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "    print('average step time ({} steps): {}s'.format(step, avg_time/step))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaba766f-ad07-4c19-9ba6-297fa735145f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Multi-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac9221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_id = 'CrowdSim-v0'\n",
    "# env_id = 'CrowdSimVarNum-v0'\n",
    "# env_id = 'CrowdSimSgan-v0'\n",
    "\n",
    "num_cpu = 4  # Number of processes to use\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc0e6a8-965c-485d-98ed-f3ba3099fd11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_env(seed, rank, env_config, envNum=1):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "\n",
    "    :param env_id: (str) the environment ID\n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    \"\"\"\n",
    "\n",
    "    def _init():\n",
    "        env = CrowdSimSgan()\n",
    "        # use a seed for reproducibility\n",
    "        # Important: use a different seed for each environment\n",
    "        # otherwise they would generate the same experiences\n",
    "        env.seed(seed + rank)\n",
    "        env.setup(seed=seed+rank, num_of_env=envNum)\n",
    "        env.configure(env_config)\n",
    "        return env\n",
    "\n",
    "    return _init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545b71de",
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = SubprocVecEnv([make_env(seed, i, config, num_cpu) for i in range(num_cpu)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
